Contributions: 
1.    Introduce CSWMs: structured models for learning abstract state representations from objects in an environment.  The paper demonstrates use of structured priors in environment modelling to induce a bias in the learning process. 
2.     Adapts an object level contrastive loss to learn state representations.  A connection is established with KB graph embeddings approach and the improvements in both the fields can be transferred among the fields. 
3.    Used ranking based eval metrics. A generated next state is compared with a set of reference states.  

The paper is well written and easy to read. The design decisions are justified with extensive ablation studies in the appendix.  The paper shows promising approach to learn state representations by inducing some structure in the modelling of the problem. 

The paper introduces CSWMs to learn state representations from a completely offline buffer of observations. Each state is represented as K feature maps, each depicting an object in the environment. The action space is decomposed into k one-hot vectors, each depicting application of an action to the corresponding object.  Energy based contrastive loss is used to learn the state representations and the transition functions. All the objects are treated as nodes in a fully connected graph and a GNN learns the impact of the action and other objects on a particular object. This is done for all k objects.  A natural extension to this is adding multi-modal information about the environment, like audio/text commands, IMU data etc.  

The evaluation is done over 5 environments: 2D shapes, 3D blocks, Atari Pong Game and Space Invaders and 3-Body physics problem.  All the environments are toy environments with little complexity. The qualitative results seem very strong, the model learns to figure out the object location in the masks and transition functions.  The quantitative results show superior results as compared the baselines. But the domains are simple, without involving much complication. Some results on a complicated domain would be good, since authors have mentioned training stability issues with complicated games. Some experiments involving studying the effect of K would have been helpful. The current results show no conclusive pattern though I expected that large K values should be helpful.  

A good future extension of the approach would be to use multimodal feature maps/hierarchical feature maps to enable coarse action space.  Also, currently pairwise interaction among objects is considered, to make it more general, directed edges can be considered or weighted edges. The paper uses a finite action space represented as on-hot vectors for each object in the state representation. Maybe further steps could be using embeddings for actions to support fine grained actions and possibly infinite actions.  